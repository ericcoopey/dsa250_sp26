{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dec5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37be0e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send a request to the website\n",
    "url = \"http://books.toscrape.com/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Successfully connected to the website!\")\n",
    "else:\n",
    "    print(\"Failed to connect.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd871e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "print(soup.prettify()[:1000])  # Print the first 1000 characters of the HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4473570",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "print(f\"Found {len(books)} books on the page.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff6adcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data (e.g., book titles and prices)\n",
    "data = []\n",
    "for book in books:\n",
    "    title = book.h3.a[\"title\"]\n",
    "    price = book.find(\"p\", class_=\"price_color\").text\n",
    "    data.append({\"Title\": title, \"Price\": price})\n",
    "\n",
    "# Display the first few entries\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26828449",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21194a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"books.csv\", index=False)\n",
    "print(\"Data saved to 'books.csv'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f059364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'http://books.toscrape.com/catalogue/page-3.html'\n",
    "\n",
    "response2 = requests.get(url2)\n",
    "if response2.status_code == 200:\n",
    "    print(\"Successfully connected to the second page!\")\n",
    "else:\n",
    "    print(\"Failed to connect to the second page.\")\n",
    "\n",
    "soup2 = BeautifulSoup(response2.text, \"html.parser\")\n",
    "books2 = soup2.find_all(\"article\", class_=\"product_pod\")\n",
    "data = []\n",
    "for book in books2:\n",
    "    title = book.h3.a[\"title\"]\n",
    "    price = book.find(\"p\", class_=\"price_color\").text\n",
    "    data.append({\"Title\": title, \"Price\": price})\n",
    "\n",
    "# Display the first few entries\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4df11f7",
   "metadata": {},
   "source": [
    "Lets see if we can get some data from ESPN:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d831c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send a request to the website\n",
    "espnurl = \"https://www.espn.com/nhl/standings\"\n",
    "# create user-agent header to mimic a browser request\n",
    "response = requests.get(espnurl)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Successfully connected to the website!\")\n",
    "else:\n",
    "    print(\"Failed to connect.\" + str(response.status_code))\n",
    "\n",
    "# REQUEST FAILED???? Yes, ESPN blocks requests that don't come from a browser.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1d3cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a user-agent header to mimic a browser request\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "response = requests.get(espnurl, headers=headers)\n",
    "if response.status_code == 200:\n",
    "    print(\"Successfully connected to the website with headers!\")\n",
    "else:\n",
    "    print(\"Failed to connect.\" + str(response.status_code))\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "print(soup.prettify()[:1000])  # Print the first 1000\n",
    "\n",
    "# using beautifulsoup, get all objects with class \"team-link\"\n",
    "teams = soup.find_all(\"div\", class_=\"team-link\")\n",
    "print(f\"Found {len(teams)} teams on the page.\")\n",
    "for team in teams:\n",
    "    print(team.text.strip())\n",
    "\n",
    "# using soup, import the entire table in the div mt4\n",
    "table = soup.find(\"table\", class_=\"Table\")\n",
    "df = pd.read_html(str(table))[0]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d423694",
   "metadata": {},
   "source": [
    "# IN CLASS EXERCISE #\n",
    "\n",
    "Take this code snippet and alter it to scrape the W/L/D records for each team\n",
    "\n",
    "OR \n",
    "\n",
    "Use it to get the list of goal leaders and some of their associated state, https://www.espn.com/nhl/stats/player/_/view/skating/table/offensive/sort/goals/dir/desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89da768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add a user-agent header to mimic a browser request\n",
    "nhlurl = \"https://gochathamcougars.com/sports/mens-basketball/stats/\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "response = requests.get(nhlurl, headers=headers)\n",
    "if response.status_code == 200:\n",
    "    print(\"Successfully connected to the website with headers!\")\n",
    "else:\n",
    "    print(\"Failed to connect.\" + str(response.status_code))\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# showt he first 1000 characters of the html\n",
    "print(soup.prettify()[:1000])  # Print the first 1000\n",
    "\n",
    "# using soup, import the entire table in the div mt4\n",
    "table = soup.find(\"table\", class_=\"iITVLX\")\n",
    "\n",
    "#show the table html\n",
    "print(table.prettify()[:1000])  # Print the first 1000 characters\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsa250",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
